{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "This assignment will give you a real (active) research topic that I've discussed a little bit in class: predicting carbon storage as a function of high-resolution gridded data. In the class google drive you will find all the data you need in the Soyo_tile folder.\n",
                "\n",
                "This assignment will have you use the automated variable selection approach within LASSO to deal with a common situation in regressions on raster-stacks: we have so much data everything is significant but will lead to massive overfitting. The basic approach used here will involve reading in 2d rasters, flattening them into a 1d column ready to add to a dataframe shaped object, which we will use as our X matrix.\n",
                "\n",
                "Please turn in the completed Notebook (.ipynb) file that includes the results you generate. \n",
                "\n",
                "Below is some starter code along with specific assignment questions.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load libraries\n",
                "import numpy as np\n",
                "import os\n",
                "from osgeo import gdal\n",
                "from sklearn.linear_model import Lasso\n",
                "from matplotlib import pyplot as plt\n",
                "import statsmodels\n",
                "from statsmodels.api import OLS\n",
                "import matplotlib.pyplot as plt\n",
                "from sklearn.feature_selection import SelectFromModel\n",
                "from sklearn.linear_model import LassoCV, Lasso\n",
                "from sklearn.metrics import mean_squared_error, r2_score\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 1: Download the data and set paths\n",
                "\n",
                "Download the latest data from the class's google drive. In there, you will need the the files in `Data/python_assignment_2` data and assign a relative path to the `soyo_tile` directory in that assignment directory. It is your task to ensure your script runs in the right location and the data is stored in the right location that this relative path works."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Step 1 code\n",
                "#define the data relative path\n",
                "import os, random\n",
                "data_dir = '../../../../data/soyo_tile' "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 2: Set raster paths \n",
                "\n",
                "Assign each of the raster paths in the directory to a dictionary for later use. I've included most of the code (so you don't have to waste your time typing), but add in the missing paths."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Step 2 code\n",
                "\n",
                "raster_paths = {}\n",
                "\n",
                "# First is the dependent varable, Above Ground Carbon (AGB) in tons, measured \n",
                "# at 30 meters globally (here it is clipped to a smaller area)\n",
                "raster_paths['agb_observed_baccini_2000_30m'] = os.path.join(data_dir, \"agb_observed_baccini_2000_30m.tif\")\n",
                "\n",
                "# Here are some of the independent variables\n",
                "raster_paths['CRFVOL_M_sl1_250m'] = os.path.join(data_dir, \"CRFVOL_M_sl1_250m.tif\")\n",
                "raster_paths['HISTPR_250m'] = os.path.join(data_dir, \"HISTPR_250m.tif\")\n",
                "raster_paths['OCDENS_M_sl1_250m'] = os.path.join(data_dir, \"OCDENS_M_sl1_250m.tif\")\n",
                "raster_paths['PHIHOX_M_sl1_250m'] = os.path.join(data_dir, \"PHIHOX_M_sl1_250m.tif\")\n",
                "raster_paths['roughness_30s'] = os.path.join(data_dir, \"roughness_30s.tif\")\n",
                "raster_paths['SLGWRB_250m'] = os.path.join(data_dir, \"SLGWRB_250m.tif\")\n",
                "raster_paths['SLTPPT_M_sl1_250m'] = os.path.join(data_dir, \"SLTPPT_M_sl1_250m.tif\")\n",
                "raster_paths['terrain_ruggedness_index_30s'] = os.path.join(data_dir, \"terrain_ruggedness_index_30s.tif\")\n",
                "raster_paths['TEXMHT_M_sl1_250m'] = os.path.join(data_dir, \"TEXMHT_M_sl1_250m.tif\")\n",
                "raster_paths['wc2.0_bio_30s_01'] = os.path.join(data_dir, \"wc2.0_bio_30s_01.tif\")\n",
                "raster_paths['alt_30s'] = os.path.join(data_dir, \"alt_30s.tif\")\n",
                "raster_paths['AWCh1_M_sl1_250m'] = os.path.join(data_dir, \"AWCh1_M_sl1_250m.tif\")\n",
                "raster_paths['BDRICM_M_250m'] = os.path.join(data_dir, \"BDRICM_M_250m.tif\")\n",
                "raster_paths['BDRLOG_M_250m'] = os.path.join(data_dir, \"BDRLOG_M_250m.tif\")\n",
                "raster_paths['BLDFIE_M_sl1_250m'] = os.path.join(data_dir, \"BLDFIE_M_sl1_250m.tif\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "dict_keys(['agb_observed_baccini_2000_30m', 'CRFVOL_M_sl1_250m', 'HISTPR_250m', 'OCDENS_M_sl1_250m', 'PHIHOX_M_sl1_250m', 'roughness_30s', 'SLGWRB_250m', 'SLTPPT_M_sl1_250m', 'terrain_ruggedness_index_30s', 'TEXMHT_M_sl1_250m', 'wc2.0_bio_30s_01', 'alt_30s', 'AWCh1_M_sl1_250m', 'BDRICM_M_250m', 'BDRLOG_M_250m', 'BLDFIE_M_sl1_250m'])\n"
                    ]
                }
            ],
            "source": [
                "print(raster_paths.keys())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 3: Open the rasters\n",
                "\n",
                "Our dependent variable will be 30 meter observations of carbon storage from Baccini et al. (unpublished, but soon to be published) data. The label I assigned in the dictionary above was agb_observed_baccini_2000_30m for this variable. Use gdal.Open, GetRasterBand(1) and ReadAsArray() to read this geotiff as a numpy file\n",
                "\n",
                "Side note: If you get an error like: \"ERROR 4: This is a BigTIFF file.  BigTIFF is not supported by this version of GDAL and libtiff.\" make sure you have installed gdal with the mamba method from lecture 1. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Shape of dependent variable: (2000, 2000)\n"
                    ]
                }
            ],
            "source": [
                "# Step 3 code\n",
                "#here we use the function load_array to load raster into a numpy array.\n",
                "def load_array(input_raster_path):\n",
                "    \"\"\"Load a raster into a numpy array\"\"\"\n",
                "    raster = gdal.Open(input_raster_path)\n",
                "    band = raster.GetRasterBand(1)\n",
                "    array = band.ReadAsArray()\n",
                "    return array\n",
                "\n",
                "#load the dependent variable as numpy array\n",
                "array = raster_paths['agb_observed_baccini_2000_30m']\n",
                "agb_observed = load_array(array)\n",
                "print(\"Shape of dependent variable:\",agb_observed.shape)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 4: Define some arrays\n",
                "\n",
                "Create an empty numpy array (or full of zeros) of the right shape to house all our raster data. A very CPU-efficient way of arranging a stack of 2d rasters (which would be 3d once stacked up), is to flatten each 2d raster into a longer 1d array. This will go into our X matrix. In order to create the right sized X matrix, first get the n_obs and n_vars by inspecting the dependent variable raster and the dictionary of inputs above. Note that the n_vars should be the number of independent AND dependent variables."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "16\n",
                        "Shape: (4000000, 16)\n"
                    ]
                }
            ],
            "source": [
                "# Step 4 code\n",
                "# Get the shape of the dependent variable raster\n",
                "n_obs = agb_observed.shape[0] * agb_observed.shape[1]  \n",
                "\n",
                "# Count the number of variables (including dependent variable)\n",
                "n_vars = len(raster_paths)\n",
                "print(n_vars)\n",
                "\n",
                "# Create an empty array filled with zeros\n",
                "data_array = np.zeros((n_obs, n_vars))\n",
                "print(\"Shape:\",data_array.shape)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 5: Load all the independent variables\n",
                "\n",
                "- Iterate through the dictionary and load each raster as a 2d array\n",
                "- flatten it to 1d using the .flatten() method in numpy\n",
                "- Assign this 1d array to the correct column of the data array. By convention, the depvar will be the first column.\n",
                "\n",
                "Hint, assuming you have arranged your X array in the correct way, it should have observations (pixels) as rows and variables as cols. Given that each flattened array is for one variable and is as long as there are rows, a convenient way of assigning it would be to use numpy slice notation, potentially similar to:\n",
                "\n",
                "`data_array[:, column_index_integer]`\n",
                "\n",
                "The first colon just denotes the whole row and the column index is an integer you could create pointing to the right row.\n",
                "\n",
                "Some incomplete code to get you started is below."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loading ../../../../data/soyo_tile/agb_observed_baccini_2000_30m.tif\n",
                        "Loading ../../../../data/soyo_tile/CRFVOL_M_sl1_250m.tif\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loading ../../../../data/soyo_tile/HISTPR_250m.tif\n",
                        "Loading ../../../../data/soyo_tile/OCDENS_M_sl1_250m.tif\n",
                        "Loading ../../../../data/soyo_tile/PHIHOX_M_sl1_250m.tif\n",
                        "Loading ../../../../data/soyo_tile/roughness_30s.tif\n",
                        "Loading ../../../../data/soyo_tile/SLGWRB_250m.tif\n",
                        "Loading ../../../../data/soyo_tile/SLTPPT_M_sl1_250m.tif\n",
                        "Loading ../../../../data/soyo_tile/terrain_ruggedness_index_30s.tif\n",
                        "Loading ../../../../data/soyo_tile/TEXMHT_M_sl1_250m.tif\n",
                        "Loading ../../../../data/soyo_tile/wc2.0_bio_30s_01.tif\n",
                        "Loading ../../../../data/soyo_tile/alt_30s.tif\n",
                        "Loading ../../../../data/soyo_tile/AWCh1_M_sl1_250m.tif\n",
                        "Loading ../../../../data/soyo_tile/BDRICM_M_250m.tif\n",
                        "Loading ../../../../data/soyo_tile/BDRLOG_M_250m.tif\n",
                        "Loading ../../../../data/soyo_tile/BLDFIE_M_sl1_250m.tif\n",
                        "['agb_observed_baccini_2000_30m', 'CRFVOL_M_sl1_250m', 'HISTPR_250m', 'OCDENS_M_sl1_250m', 'PHIHOX_M_sl1_250m', 'roughness_30s', 'SLGWRB_250m', 'SLTPPT_M_sl1_250m', 'terrain_ruggedness_index_30s', 'TEXMHT_M_sl1_250m', 'wc2.0_bio_30s_01', 'alt_30s', 'AWCh1_M_sl1_250m', 'BDRICM_M_250m', 'BDRLOG_M_250m', 'BLDFIE_M_sl1_250m']\n",
                        "(4000000, 16)\n"
                    ]
                }
            ],
            "source": [
                "# Step 5 code\n",
                "feature_names = []\n",
                "\n",
                "for col_index, (name, path) in enumerate(raster_paths.items()):\n",
                "    print('Loading', path)\n",
                "    raster_array = load_array(path)  # Load raster data\n",
                "    flattened_raster_array = raster_array.flatten()  # Flatten into a 1D array\n",
                "    data_array[:, col_index] = flattened_raster_array  # Assign to the correct column\n",
                "    feature_names.append(name)  # Store feature names\n",
                "\n",
                "print(feature_names)\n",
                "print(data_array.shape)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Step 6: \n",
                "\n",
                "Extract the first array row of the data_array and assign it to y. Assign the rest to X."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "(4000000,)\n",
                        "(4000000, 15)\n"
                    ]
                }
            ],
            "source": [
                "# Step 6 code\n",
                "\n",
                "# Extracting y (our dependent variable)\n",
                "\n",
                "y = data_array[:, 0]  \n",
                "print(y.shape)\n",
                "\n",
                "# Extracting X (our independent variables)\n",
                "X = data_array[: ,1:]  \n",
                "print(X.shape)\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Step 7:\n",
                "\n",
                "Split the X and y into testing and training data such that the training data is the first million pixels and the testing data is the next 200,000. Do this using numpy slice notation on the X and y variables you created."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Step 7 code\n",
                "# Splitting X and y into training and testing sets using NumPy slice notation\n",
                "X_train = X[:1000000]\n",
                "X_test = X[-200000:]\n",
                "y_train = y[:1000000]\n",
                "y_test = y[-200000:]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Step 8 (optional but useful):\n",
                "\n",
                "To make the code run faster, we are going to use every 10th pixel. We can easily get this via numpy slicing again, using x_train[::10] to get every 10th pixel."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Step 8 code\n",
                "X_train = X_train[::10]\n",
                "y_train = y_train[::10]\n",
                "X_test = X_test[::10]\n",
                "y_test = y_test[::10]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Step 9:\n",
                "\n",
                "Create a Lasso object (using the default penalty term alpha) and fit it to the training data. Create and print out a vector of predicted carbon values. Also print out the score using the lasso object's .score() method on the TESTING data. Print out the fitted lasso score."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Lasso(max_iter=10000, random_state=0)\n"
                    ]
                }
            ],
            "source": [
                "# Step 9 code\n",
                "# Create an empty Lasso object with a few initial parameters set\n",
                "model_lasso = Lasso(alpha=1.0, random_state=0, max_iter=10000)\n",
                "y_train_hat_lasso = model_lasso.fit(X_train, y_train)\n",
                "print(model_lasso)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Predicted carbon values: [66.6869377  64.74660367 69.07640951 ... 90.60592619 89.33928596\n",
                        " 74.39677148]\n"
                    ]
                }
            ],
            "source": [
                "y_train_hat_lasso = model_lasso.predict(X_train)\n",
                "print('Predicted carbon values:', y_train_hat_lasso)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Accuracy on train set: 0.5943975260169662\n"
                    ]
                }
            ],
            "source": [
                "score= model_lasso.score(X_train, y_train)\n",
                "print(\"Accuracy on train set:\", score)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Accuracy on test set: 0.5097471522100042\n"
                    ]
                }
            ],
            "source": [
                "score = model_lasso.score(X_test, y_test)\n",
                "\n",
                "print(\"Accuracy on test set:\", score)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Step 10, optional and just for fun:.\n",
                "\n",
                "To view how our projections LOOK, we can create a predicted matrix on the whole X, reshape it back into the original 2d shape and look at it. You can compare this to the input array to visualize how it looks. Note that this will only work if you name your objects like mine."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Step 10 code"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Step 11:\n",
                "\n",
                "Create a list of 30 alphas using ` np.logspace(-1, 3, 30)`. \n",
                "\n",
                "Using a for loop iterate over those alphas and run the Lasso model like above, but using the alpha values in the loop. Print out the fit score at each step. Using matplotlib, plot how this value changes as alpha changes. Finally, extract the best alpha of the bunch. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Alpha: 0.1 Score: 0.49281221653744667\n",
                        "Alpha: 0.1373823795883263 Score: 0.49364982587428985\n",
                        "Alpha: 0.18873918221350972 Score: 0.4947816945001292\n",
                        "Alpha: 0.2592943797404667 Score: 0.4963006921708921\n",
                        "Alpha: 0.3562247890262442 Score: 0.4983197104806468\n",
                        "Alpha: 0.4893900918477494 Score: 0.5009660869267845\n",
                        "Alpha: 0.6723357536499337 Score: 0.5043613628715736\n",
                        "Alpha: 0.9236708571873861 Score: 0.5085721749191421\n",
                        "Alpha: 1.2689610031679222 Score: 0.5124513710336216\n",
                        "Alpha: 1.743328822199988 Score: 0.5154271242406102\n",
                        "Alpha: 2.395026619987486 Score: 0.5174592640326362\n",
                        "Alpha: 3.2903445623126677 Score: 0.5198426609470972\n",
                        "Alpha: 4.520353656360243 Score: 0.5201536562062508\n",
                        "Alpha: 6.2101694189156165 Score: 0.5167502877628407\n",
                        "Alpha: 8.531678524172806 Score: 0.5100852430540102\n",
                        "Alpha: 11.721022975334806 Score: 0.49358248366080293\n",
                        "Alpha: 16.102620275609393 Score: 0.4652163390026889\n",
                        "Alpha: 22.12216291070448 Score: 0.42348804392372696\n",
                        "Alpha: 30.39195382313198 Score: 0.3478559630012372\n",
                        "Alpha: 41.753189365604 Score: 0.3293012716571957\n",
                        "Alpha: 57.361525104486816 Score: 0.3054427766495096\n",
                        "Alpha: 78.80462815669912 Score: 0.25356543847589597\n",
                        "Alpha: 108.2636733874054 Score: 0.25354106050233804\n",
                        "Alpha: 148.73521072935117 Score: 0.25204854317573955\n",
                        "Alpha: 204.33597178569417 Score: 0.24724616665826948\n",
                        "Alpha: 280.72162039411756 Score: 0.23545679129974117\n",
                        "Alpha: 385.6620421163472 Score: 0.20946138865760322\n",
                        "Alpha: 529.8316906283708 Score: 0.1552539632755583\n",
                        "Alpha: 727.8953843983146 Score: 0.08678236883018442\n",
                        "Alpha: 1000.0 Score: 0.054262942529912817\n",
                        "Best Alpha for Test Scores: 4.520353656360243\n"
                    ]
                }
            ],
            "source": [
                "#Step 11 code\n",
                "#empty list to store the score\n",
                "test_scores = {}\n",
                "#list of 30 alphas\n",
                "alphas = np.logspace(-1, 3, 30)\n",
                "\n",
                "for alpha in alphas:\n",
                "    model_lasso = Lasso(alpha=alpha, random_state=0, max_iter=10000)\n",
                "    model_lasso.fit(X_train, y_train)\n",
                "    score = model_lasso.score(X_test, y_test)\n",
                "    test_scores[alpha] = score\n",
                "    print('Alpha:', alpha, 'Score:', score)\n",
                "\n",
                "best_alpha_test = max(test_scores, key=test_scores.get)\n",
                "best_alpha = best_alpha_test\n",
                "print('Best Alpha for Test Scores:', best_alpha_test)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "image/png": "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",
                        "text/plain": [
                            "<Figure size 1000x600 with 1 Axes>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Best Alpha for Test Scores: 4.520353656360243\n"
                    ]
                }
            ],
            "source": [
                "# Here, I insert the code to make plot inside the loop. I did take some help\n",
                "#to nicely label the plot.\n",
                "\n",
                "test_scores = {}\n",
                "alphas = np.logspace(-1, 3, 30)\n",
                "\n",
                "best_alpha = None\n",
                "best_alpha_test = None\n",
                "\n",
                "plt.figure(figsize=(10, 6))\n",
                "\n",
                "for alpha in alphas:\n",
                "    model_lasso = Lasso(alpha=alpha, random_state=0, max_iter=10000)\n",
                "    model_lasso.fit(X_train, y_train)\n",
                "    score = model_lasso.score(X_test, y_test)\n",
                "    test_scores[alpha] = score\n",
                "    \n",
                "    # Find best alpha for test scores\n",
                "    if best_alpha_test is None or score > test_scores[best_alpha_test]:\n",
                "        best_alpha_test = alpha\n",
                "\n",
                "    plt.scatter(alpha, score, color='blue')\n",
                "\n",
                "# Plotting\n",
                "plt.axvline(best_alpha_test, linestyle='--', color='red', \n",
                "            label='Best Alpha for Test Scores')\n",
                "plt.xscale('log')\n",
                "plt.xlabel('Alpha')\n",
                "plt.ylabel('Score ')\n",
                "plt.title('Alpha vs. Test Scores')\n",
                "plt.legend()\n",
                "plt.grid(True)\n",
                "plt.show()\n",
                "\n",
                "print('Best Alpha for Test Scores:', best_alpha_test)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Step 12: \n",
                "\n",
                "Rerun the lasso with that best value and identify all of the coefficiencts that were \"selected\" ie had non-zero values. Save these coefficient indices and labels to a list."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Coefficients: [ 0.          0.63974061  0.24462421 -6.22075713 -0.         -0.\n",
                        " -0.          0.32890017 -5.36312292  0.         -0.07871124 -0.\n",
                        "  4.34081434  1.14100755 -0.32220005]\n"
                    ]
                }
            ],
            "source": [
                "# Step 12 code\n",
                "\n",
                "#reruning the same steps as above with best alpha that we identified above\n",
                "lasso_2 = Lasso(alpha = 4.520353656360243, random_state = 0, max_iter = 10000).fit(X_train, y_train)\n",
                "\n",
                "print(\"Coefficients:\", lasso_2.coef_)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "['agb_observed_baccini_2000_30m', 'CRFVOL_M_sl1_250m', 'HISTPR_250m', 'OCDENS_M_sl1_250m', 'PHIHOX_M_sl1_250m', 'roughness_30s', 'SLGWRB_250m', 'SLTPPT_M_sl1_250m', 'terrain_ruggedness_index_30s', 'TEXMHT_M_sl1_250m', 'wc2.0_bio_30s_01', 'alt_30s', 'AWCh1_M_sl1_250m', 'BDRICM_M_250m', 'BDRLOG_M_250m', 'BLDFIE_M_sl1_250m']\n",
                        "['CRFVOL_M_sl1_250m', 'HISTPR_250m', 'OCDENS_M_sl1_250m', 'PHIHOX_M_sl1_250m', 'roughness_30s', 'SLGWRB_250m', 'SLTPPT_M_sl1_250m', 'terrain_ruggedness_index_30s', 'TEXMHT_M_sl1_250m', 'wc2.0_bio_30s_01', 'alt_30s', 'AWCh1_M_sl1_250m', 'BDRICM_M_250m', 'BDRLOG_M_250m', 'BLDFIE_M_sl1_250m']\n"
                    ]
                }
            ],
            "source": [
                "#A thing to realize is that the features_name list we created in Step 5 include \n",
                "#\"agb_observed_baccini_2000_30m\" (our dependent variable) as the first element,\n",
                "# so we create a new list of independent variables only\n",
                "\n",
                "print(feature_names)\n",
                "feature_name = feature_names[1:]\n",
                "print(feature_name)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Coefficient CRFVOL_M_sl1_250m was 0.0\n",
                        "Coefficient HISTPR_250m was 0.6397406121398291\n",
                        "Coefficient OCDENS_M_sl1_250m was 0.24462421409903706\n",
                        "Coefficient PHIHOX_M_sl1_250m was -6.220757126363239\n",
                        "Coefficient roughness_30s was -0.0\n",
                        "Coefficient SLGWRB_250m was -0.0\n",
                        "Coefficient SLTPPT_M_sl1_250m was -0.0\n",
                        "Coefficient terrain_ruggedness_index_30s was 0.32890016787035947\n",
                        "Coefficient TEXMHT_M_sl1_250m was -5.3631229245726155\n",
                        "Coefficient wc2.0_bio_30s_01 was 0.0\n",
                        "Coefficient alt_30s was -0.07871124274874718\n",
                        "Coefficient AWCh1_M_sl1_250m was -0.0\n",
                        "Coefficient BDRICM_M_250m was 4.340814344592574\n",
                        "Coefficient BDRLOG_M_250m was 1.1410075474188568\n",
                        "Coefficient BLDFIE_M_sl1_250m was -0.3222000466550357\n"
                    ]
                }
            ],
            "source": [
                "#now we identify the selected coefficients among the 15 independent variables\n",
                "\n",
                "selected_coefficient_labels = []\n",
                "selected_coefficient_indices = []\n",
                "for i in range(len(lasso_2.coef_)):\n",
                "    print('Coefficient', feature_name[i], 'was', lasso_2.coef_[i])\n",
                "    if abs(lasso_2.coef_[i]) > 0:\n",
                "        selected_coefficient_labels.append(feature_name[i])\n",
                "        selected_coefficient_indices.append(i)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "selected_coefficient_labels ['HISTPR_250m', 'OCDENS_M_sl1_250m', 'PHIHOX_M_sl1_250m', 'terrain_ruggedness_index_30s', 'TEXMHT_M_sl1_250m', 'alt_30s', 'BDRICM_M_250m', 'BDRLOG_M_250m', 'BLDFIE_M_sl1_250m']\n"
                    ]
                }
            ],
            "source": [
                "#following this we get the list of our selected coefficients\n",
                "print('selected_coefficient_labels', selected_coefficient_labels)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Step 13:\n",
                "\n",
                "Using Statsmodels, run an OLS version on the selected variables.\n",
                "\n",
                "Use print to show the results table.\n",
                "\n",
                "Write a description of any advantages this approach has over vanilla OLS.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "(100000, 9)\n",
                        "(100000,)\n"
                    ]
                }
            ],
            "source": [
                "#prepare our X and y variable for OLS \n",
                "X_train_selected = X_train[:, selected_coefficient_indices]\n",
                "print(X_train_selected.shape)\n",
                "print(y_train.shape)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "                            OLS Regression Results                            \n",
                        "==============================================================================\n",
                        "Dep. Variable:                      y   R-squared:                       0.592\n",
                        "Model:                            OLS   Adj. R-squared:                  0.592\n",
                        "Method:                 Least Squares   F-statistic:                 1.612e+04\n",
                        "Date:                Fri, 08 Dec 2023   Prob (F-statistic):               0.00\n",
                        "Time:                        17:51:32   Log-Likelihood:            -5.1551e+05\n",
                        "No. Observations:              100000   AIC:                         1.031e+06\n",
                        "Df Residuals:                   99990   BIC:                         1.031e+06\n",
                        "Df Model:                           9                                         \n",
                        "Covariance Type:            nonrobust                                         \n",
                        "==============================================================================\n",
                        "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
                        "------------------------------------------------------------------------------\n",
                        "const          1.2923      1.332      0.970      0.332      -1.319       3.904\n",
                        "x1             3.6162      0.105     34.350      0.000       3.410       3.823\n",
                        "x2             0.1718      0.004     41.606      0.000       0.164       0.180\n",
                        "x3            -7.6015      0.068   -111.289      0.000      -7.735      -7.468\n",
                        "x4             0.3855      0.013     30.529      0.000       0.361       0.410\n",
                        "x5            -7.8343      0.116    -67.327      0.000      -8.062      -7.606\n",
                        "x6             0.0019      0.005      0.368      0.713      -0.008       0.012\n",
                        "x7             4.4929      0.033    137.763      0.000       4.429       4.557\n",
                        "x8             1.5814      0.048     32.883      0.000       1.487       1.676\n",
                        "x9            -0.2748      0.004    -62.284      0.000      -0.283      -0.266\n",
                        "==============================================================================\n",
                        "Omnibus:                     4827.615   Durbin-Watson:                   1.321\n",
                        "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             6307.272\n",
                        "Skew:                           0.486   Prob(JB):                         0.00\n",
                        "Kurtosis:                       3.755   Cond. No.                     1.39e+04\n",
                        "==============================================================================\n",
                        "\n",
                        "Notes:\n",
                        "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
                        "[2] The condition number is large, 1.39e+04. This might indicate that there are\n",
                        "strong multicollinearity or other numerical problems.\n"
                    ]
                }
            ],
            "source": [
                "#run the regression\n",
                "import statsmodels\n",
                "from statsmodels.api import OLS\n",
                "\n",
                "# Add a constant term \n",
                "X_with_constant = statsmodels.api.add_constant(X_train_selected)\n",
                "#store the result and print it\n",
                "result = OLS(y_train, X_with_constant).fit().summary()\n",
                "print(result)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The obvious advantage of this approach over vanilla OLS is that we get to use only those coefficients \n",
                "that have an impact on the dependent variable (y), naturally improving the model efficieny."
            ]
        }
    ],
    "metadata": [
        {
            "kernelspec": {
                "display_name": "Python 3 (ipykernel)",
                "language": "python",
                "name": "python3"
            }
        }
    ],
    "nbformat": 4,
    "nbformat_minor": 4
}
